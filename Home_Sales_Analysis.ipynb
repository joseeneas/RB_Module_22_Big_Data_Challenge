{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE 22 - BIG DATA ANALYSIS WITH SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0 - Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_KW73O2e3dw",
    "notebookRunGroups": {
     "groupValue": ""
    },
    "outputId": "78c91763-b7de-43b3-ae23-1fb13e566086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:36.977108 \u001b[33mSTEP 0 - ENVIRONMENT PREPARATION======================\u001b[37m\n",
      "\u001b[32m\n",
      "Copyright        : Copyright (c) 2001-2023 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved.\n",
      "OS Platform      : darwin\n",
      "OS Name          : posix\n",
      "OS HOME          : /Users/eneas\n",
      "OS uName         : Darwin\n",
      "OS NodeName      : MBPJES14M2.local\n",
      "OS Release       : 23.0.0\n",
      "OS Release Ver   : Darwin Kernel Version 23.0.0: Tue Aug 22 02:11:55 PDT 2023; root:xnu-10002.1.11~16/RELEASE_ARM64_T6020\n",
      "OS Machine       : arm64\n",
      "Process ID       : 5342\n",
      "Parent Process   : 1765\n",
      "OS User          : root\n",
      "OS User ID       : 501\n",
      "OS Group ID      : 20\n",
      "OS Effective ID  : 501\n",
      "OS Effective GID : 20\n",
      "Current dir      : /Users/eneas/Documents/GitHub/RB_Module_22_Big_Data_Challenge\n",
      "Python version   : 3.11.5 | packaged by conda-forge | (main, Aug 27 2023, 03:33:12) [Clang 15.0.7 ]\n",
      "Version info     : sys.version_info(major=3, minor=11, micro=5, releaselevel='final', serial=0)\n",
      "Python API Ver   : 1013\n",
      "Executable       : /Users/eneas/anaconda3/envs/myProd/bin/python\n",
      "Hadoop home      : None\n",
      "Spark version    : 2.0.1\n",
      "Spark home(Find) : /Users/eneas/anaconda3/envs/myProd/lib/python3.11/site-packages/pyspark\n",
      "Spark Home(Env)  : None\n",
      "Spark UI         : http://localhost:4040\n",
      "Spark submit     : /Users/eneas/anaconda3/envs/myProd/lib/python3.11/site-packages/ipykernel_launcher.py\n",
      "Java home        : /Users/eneas/anaconda3/envs/myProd\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:37.087107 \u001b[33mSTEP 0 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:37.088063 \u001b[33mSTEP 0 - ELAPSED TIME: 0:00:00.110893 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 0 - Environment Setup\n",
    "#\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from   colorama import Fore\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "def logStep(msg):\n",
    "    print(Fore.WHITE + str(datetime.datetime.now()) + ' ' + Fore.YELLOW + msg + Fore.WHITE)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "logStep('STEP 0 - ENVIRONMENT PREPARATION======================')\n",
    "\n",
    "import warnings   \n",
    "import findspark                           \n",
    "from   pyspark     import SparkFiles  \n",
    "from   pyspark.sql import SparkSession\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(Fore.GREEN)\n",
    "print(F'Copyright        : {sys.copyright}')\n",
    "print(F'OS Platform      : {sys.platform}')\n",
    "print(F'OS Name          : {os.name}')\n",
    "print(F'OS HOME          : {os.environ.get(\"HOME\")}')\n",
    "print(F'OS uName         : {os.uname().sysname}')\n",
    "print(F'OS NodeName      : {os.uname().nodename}')\n",
    "print(F'OS Release       : {os.uname().release}')\n",
    "print(F'OS Release Ver   : {os.uname().version}')\n",
    "print(F'OS Machine       : {os.uname().machine}')\n",
    "print(F'Process ID       : {os.getpid()}')\n",
    "print(F'Parent Process   : {os.getppid()}')\n",
    "print(F'OS User          : {os.getlogin()}')\n",
    "print(F'OS User ID       : {os.getuid()}')\n",
    "print(F'OS Group ID      : {os.getgid()}')\n",
    "print(F'OS Effective ID  : {os.geteuid()}')\n",
    "print(F'OS Effective GID : {os.getegid()}')\n",
    "print(F'Current dir      : {os.getcwd()}')\n",
    "print(F'Python version   : {sys.version}')\n",
    "print(F'Version info     : {sys.version_info}')\n",
    "print(F'Python API Ver   : {sys.api_version}')\n",
    "print(F'Executable       : {sys.executable}')\n",
    "print(F'Hadoop home      : {os.environ.get(\"HADOOP_HOME\")}')\n",
    "print(F'Spark version    : {findspark.__version__}')\n",
    "print(F'Spark home(Find) : {findspark.find()}')\n",
    "print(F'Spark Home(Env)  : {os.environ.get(\"SPARK_HOME\")}')\n",
    "print(F'Spark UI         : http://localhost:4040')\n",
    "print(F'Spark submit     : {sys.argv[0]}')\n",
    "print(F'Java home        : {os.environ.get(\"JAVA_HOME\")}')\n",
    "print()\n",
    "\n",
    "logStep(\"STEP 0 - DONE=========================================\");\n",
    "end_time           = datetime.datetime.now()\n",
    "step0_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 0 - ELAPSED TIME: {step0_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Read in the source file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOJqxG_RPSwp",
    "outputId": "69591c83-18c1-4e2a-86d4-2e5219c6d006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:14:22.368154 \u001b[33mSTEP 1 - READ SOURCE DATA=============================\u001b[37m\n",
      "\u001b[32m\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n",
      "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n",
      "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n",
      "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n",
      "|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n",
      "|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n",
      "|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n",
      "|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n",
      "|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n",
      "|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n",
      "|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n",
      "|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n",
      "|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n",
      "|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n",
      "|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n",
      "|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n",
      "|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n",
      "|4566cd2a-ac6e-435...|2019-07-15|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 1 - Spark operation - Source data read successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:14:22.462732 \u001b[33mSTEP 1 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:14:22.463189 \u001b[33mSTEP 1 - ELAPSED TIME: 0:00:00.095013 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 1 - Read in the source file into a DataFrame.\n",
    "#\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "logStep(\"STEP 1 - READ SOURCE DATA=============================\");\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  findspark.init()\n",
    "  spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "  spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "  url   = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n",
    "  spark.sparkContext.addFile(url)\n",
    "  home_df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), sep=\",\", header=True, ignoreLeadingWhiteSpace=True)\n",
    "  home_df.show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 1 - Spark operation - Source data read successfully.\")\n",
    "  print()\n",
    "\n",
    "logStep(\"STEP 1 - DONE=========================================\");\n",
    "end_time           = datetime.datetime.now()\n",
    "step1_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 1 - ELAPSED TIME: {step1_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 - Create a temporary view of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RoljcJ7WPpnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:41.795955 \u001b[33mSTEP 2 - CREATE A TEMPORARY VIEW======================\u001b[37m\n",
      "\u001b[32m\n",
      "\u001b[32mStep 2 - Spark operation - Temporary view created successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:41.813994 \u001b[33mSTEP 2 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:41.814333 \u001b[33mSTEP 2 - ELAPSED TIME: 0:00:00.018361 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 2 - Create a temporary view of the DataFrame.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 2 - CREATE A TEMPORARY VIEW======================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  home_df.createOrReplaceTempView('home_sales')\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 2 - Spark operation - Temporary view created successfully.\")\n",
    "  print()\n",
    "\n",
    "logStep(\"STEP 2 - DONE=========================================\")\n",
    "end_time           = datetime.datetime.now()\n",
    "step2_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 2 - ELAPSED TIME: {step2_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 - What is the average price for a four bedroom house sold in each year rounded to two decimal places?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6fkwOeOmqvq",
    "outputId": "7d9b6b22-c722-42dc-80c0-81e8810f7521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:41.818778 \u001b[33mSTEP 3 - WHAT IS THE AVERAGE PRICE?=4BR===============\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|YEAR|  AVERAGE|\n",
      "+----+---------+\n",
      "|2022|296363.88|\n",
      "|2021|301819.44|\n",
      "|2020|298353.78|\n",
      "|2019| 300263.7|\n",
      "+----+---------+\n",
      "\n",
      "\u001b[32mStep 3 - Spark operation - Query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:42.424221 \u001b[33mSTEP 3 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:42.424578 \u001b[33mSTEP 3 - ELAPSED TIME: 0:00:00.605779 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 3 - What is the average price for a four bedroom house sold in each year rounded to two decimal places?\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 3 - WHAT IS THE AVERAGE PRICE?=4BR===============\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT YEAR(date)          as YEAR, \\\n",
    "                  ROUND(AVG(price),2) as AVERAGE \\\n",
    "             FROM home_sales WHERE bedrooms == 4 \\\n",
    "                  GROUP BY YEAR(date) \\\n",
    "                  ORDER BY YEAR(date) desc\").show()\n",
    "except Exception as e:\n",
    "     print(Fore.RED + F\"Exception: {e}\")\n",
    "     sys.exit(1)\n",
    "else:\n",
    "     print(Fore.GREEN + \"Step 3 - Spark operation - Query executed successfully.\")\n",
    "     print()\n",
    "     \n",
    "logStep(\"STEP 3 - DONE=========================================\")\n",
    "end_time           = datetime.datetime.now()\n",
    "step3_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 3 - ELAPSED TIME: {step3_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 4 - What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8p_tUS8h8it",
    "outputId": "e1c36565-5164-4a9f-f36a-b2ad94522f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:42.428876 \u001b[33mSTEP 4 - WHAT IS THE AVERAGE PRICE?=3BR/3B============\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|YEAR|  AVERAGE|\n",
      "+----+---------+\n",
      "|2017|292676.79|\n",
      "|2016|290555.07|\n",
      "|2015| 288770.3|\n",
      "|2014|290852.27|\n",
      "|2013|295962.27|\n",
      "|2012|293683.19|\n",
      "|2011|291117.47|\n",
      "|2010|292859.62|\n",
      "+----+---------+\n",
      "\n",
      "\u001b[32mStep 4 - Spark operation - Query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:42.643897 \u001b[33mSTEP 4 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:42.644454 \u001b[33mSTEP 4 - ELAPSED TIME: 0:00:00.215014 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 4 - WHAT IS THE AVERAGE PRICE?=3BR/3B============\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT date_built as YEAR , \\\n",
    "                    ROUND(AVG(price),2) as AVERAGE  \\\n",
    "               FROM home_sales WHERE bedrooms == 3 AND \\\n",
    "                                     bathrooms == 3 \\\n",
    "                    GROUP BY date_built \\\n",
    "                    ORDER BY date_built desc\").show()    \n",
    "except Exception as e:\n",
    "     print(Fore.RED + F\"Exception: {e}\")\n",
    "     sys.exit(1)\n",
    "else:\n",
    "     print(Fore.GREEN + \"Step 4 - Spark operation - Query executed successfully.\")\n",
    "     print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 4 - DONE=========================================\")\n",
    "step4_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 4 - ELAPSED TIME: {step4_elapsed_time} seconds=========\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors, and are greater than or equal to 2,000 square feet rounded to two decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-Eytz64liDU",
    "outputId": "9b51b8bc-8d1e-4a4e-ff50-f94a621891be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:42.648828 \u001b[33mSTEP 5 - WHAT IS THE AVERAGE PRICE?=3R/3/2============\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|YEAR|  AVERAGE|\n",
      "+----+---------+\n",
      "|2017|280317.58|\n",
      "|2016| 293965.1|\n",
      "|2015|297609.97|\n",
      "|2014|298264.72|\n",
      "|2013|303676.79|\n",
      "|2012|307539.97|\n",
      "|2011|276553.81|\n",
      "|2010|285010.22|\n",
      "+----+---------+\n",
      "\n",
      "\u001b[32mStep 5 - Spark operation - Query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:42.807205 \u001b[33mSTEP 5 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:42.807531 \u001b[33mSTEP 5 - ELAPSED TIME: 0:00:00.158371 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 5 - What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors,\n",
    "# and are greater than or equal to 2,000 square feet rounded to two decimal places?\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 5 - WHAT IS THE AVERAGE PRICE?=3R/3/2============\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT date_built as YEAR, \\\n",
    "           ROUND(AVG(price),2) as AVERAGE from home_sales \\\n",
    "           where bedrooms  == 3 AND \\\n",
    "                 bathrooms == 3 AND \\\n",
    "                    floors == 2 AND \\\n",
    "               sqft_living >= 2000 \\\n",
    "                 group by date_built \\\n",
    "                 order by date_built desc\").show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 5 - Spark operation - Query executed successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 5 - DONE=========================================\")\n",
    "step5_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 5 - ELAPSED TIME: {step5_elapsed_time} seconds=========\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 - What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than or equal to $350,000? Although this is a small dataset, determine the run time for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUrfgOX1pCRd",
    "outputId": "73e46678-fca9-434f-feb8-b2460e96e41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:42.811509 \u001b[33mSTEP 6 - WHAT IS THE AVERAGE PRICE?=300K==============\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|VIEW|  AVERAGE|\n",
      "+----+---------+\n",
      "| 100|1026669.5|\n",
      "|  51|788128.21|\n",
      "|  52|733780.26|\n",
      "|  53| 755214.8|\n",
      "|  54|798684.82|\n",
      "|  55|771153.32|\n",
      "|  56| 718176.4|\n",
      "|  57| 734340.5|\n",
      "|  58|759764.65|\n",
      "|  59| 791453.0|\n",
      "|  60|754939.65|\n",
      "|  61|746877.59|\n",
      "|  62|759150.14|\n",
      "|  63|711614.55|\n",
      "|  64|767036.67|\n",
      "|  65|736679.93|\n",
      "|  66| 712475.0|\n",
      "|  67|737970.96|\n",
      "|  68|716785.44|\n",
      "|  69|750537.94|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 6 - Spark operation - Query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:43.002294 \u001b[33mSTEP 6 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:43.002668 \u001b[33mSTEP 6 - ELAPSED TIME: 0:00:00.190776 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Ste 6 - What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than or equal to $350,000? Although this is a small dataset, determine the run time for this query.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 6 - WHAT IS THE AVERAGE PRICE?=300K==============\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT view as VIEW, \\\n",
    "                  ROUND(AVG(price),2) AS AVERAGE \\\n",
    "             FROM home_sales \\\n",
    "             GROUP BY view \\\n",
    "           HAVING ROUND(AVG(price),2) >= 350000 \\\n",
    "           ORDER BY view\").show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1) \n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 6 - Spark operation - Query executed successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 6 - DONE=========================================\")\n",
    "step6_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 6 - ELAPSED TIME: {step6_elapsed_time} seconds=========\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7 - Cache the the temporary table home_sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAhk3ZD2tFy8",
    "outputId": "7a421ad4-699e-4ae1-c13e-3ac1379a3cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:43.006836 \u001b[33mSTEP 7 - CACHE HOME DATA==============================\u001b[37m\n",
      "\u001b[32m\n",
      "\u001b[32mStep 7 - Spark operation - Cache executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:43.348138 \u001b[33mSTEP 7 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:43.348516 \u001b[33mSTEP 7 - ELAPSED TIME: 0:00:00.341298 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 7 - Cache the the temporary table home_sales.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 7 - CACHE HOME DATA==============================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"cache table home_sales\")\n",
    "except Exception as e:\n",
    "    print(Fore.RED + F\"Exception: {e}\")\n",
    "    sys.exit(1) \n",
    "else:\n",
    "    print(Fore.GREEN + \"Step 7 - Spark operation - Cache executed successfully.\")\n",
    "    print()\n",
    "    \n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 7 - DONE=========================================\")\n",
    "step7_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 7 - ELAPSED TIME: {step7_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8 - Check if the table is cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4opVhbvxtL-i",
    "outputId": "3003ef79-0678-4a80-e79a-eac9fdfc8a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:43.352572 \u001b[33mSTEP 8 - IS THE DATA CACHED===========================\u001b[37m\n",
      "\u001b[32m\n",
      "home_sales is cached\n",
      "\u001b[32mStep 8 - Spark operation - Cache check executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:43.358710 \u001b[33mSTEP 8 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:43.358991 \u001b[33mSTEP 8 - ELAPSED TIME: 0:00:00.006130 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 8 - Check if the table is cached.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 8 - IS THE DATA CACHED===========================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  if (spark.catalog.isCached('home_sales') == False):\n",
    "    print(\"home_sales is not cached\")\n",
    "  else:\n",
    "    print(\"home_sales is cached\")\n",
    "except Exception as e:\n",
    "    print(Fore.RED + F\"Exception: {e}\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(Fore.GREEN + \"Step 8 - Spark operation - Cache check executed successfully.\")\n",
    "    print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 8 - DONE=========================================\")\n",
    "step8_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 8 - ELAPSED TIME: {step8_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9 - Using the cached data, run the query that filters out the view ratings with average price greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GnL46lwTSEk",
    "outputId": "a7aec34a-063b-46bc-b428-8660a32d9a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:43.362915 \u001b[33mSTEP 9 - REPEAT QUERY=================================\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|VIEW|  AVERAGE|\n",
      "+----+---------+\n",
      "| 100|1026669.5|\n",
      "|  51|788128.21|\n",
      "|  52|733780.26|\n",
      "|  53| 755214.8|\n",
      "|  54|798684.82|\n",
      "|  55|771153.32|\n",
      "|  56| 718176.4|\n",
      "|  57| 734340.5|\n",
      "|  58|759764.65|\n",
      "|  59| 791453.0|\n",
      "|  60|754939.65|\n",
      "|  61|746877.59|\n",
      "|  62|759150.14|\n",
      "|  63|711614.55|\n",
      "|  64|767036.67|\n",
      "|  65|736679.93|\n",
      "|  66| 712475.0|\n",
      "|  67|737970.96|\n",
      "|  68|716785.44|\n",
      "|  69|750537.94|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 9 - Spark operation - Query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:43.463483 \u001b[33mSTEP 9 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:43.464581 \u001b[33mSTEP 9 - ELAPSED TIME: 0:00:00.100561 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 9 - Using the cached data, run the query that filters out the view ratings with average price greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 9 - REPEAT QUERY=================================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT view as VIEW, \\\n",
    "                    ROUND(AVG(price),2) AS AVERAGE \\\n",
    "               FROM home_sales \\\n",
    "               GROUP BY view \\\n",
    "             HAVING ROUND(AVG(price),2) >= 350000 \\\n",
    "             ORDER BY view\").show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 9 - Spark operation - Query executed successfully.\")\n",
    "  print() \n",
    "  \n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 9 - DONE=========================================\")\n",
    "step9_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 9 - ELAPSED TIME: {step9_elapsed_time} seconds=========\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9.1 - Determine the runtime and compare to the original runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAYsuFaZuCmw",
    "outputId": "c5787884-c516-4f61-9956-6edfc0dcbf9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:43.469487 \u001b[33mSTEP 9.1 - RUNTIME DIFFERENCE =========================\u001b[37m\n",
      "\u001b[32m\n",
      "Time required for a non-cached Query: 0:00:00.190776\n",
      "Time required for a cached Query    : 0:00:00.100561\n",
      "Time difference                     : 0:00:00.090215\n",
      "\u001b[32m\n",
      "\u001b[37m2023-09-05 15:11:43.470579 \u001b[33mSTEP 9.1 - DONE========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:43.471106 \u001b[33mSTEP 9.1 - ELAPSED TIME: 0:00:00.001097 seconds========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 9.1 Determine the runtime and compare to the original runtime\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 9.1 - RUNTIME DIFFERENCE =========================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "print(F\"Time required for a non-cached Query: {step6_elapsed_time}\")\n",
    "print(F\"Time required for a cached Query    : {step9_elapsed_time}\")\n",
    "time_difference = step6_elapsed_time - step9_elapsed_time\n",
    "print(F\"Time difference                     : {time_difference}\")\n",
    "print(Fore.GREEN)\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 9.1 - DONE========================================\")\n",
    "step91_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 9.1 - ELAPSED TIME: {step91_elapsed_time} seconds========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10 - Partition by the \"date_built\" field on the formatted parquet home sales data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qm12WN9isHBR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:43.476915 \u001b[33mSTEP 10 - FORMATTED PARQUET============================\u001b[37m\n",
      "\u001b[32m\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n",
      "|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n",
      "|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n",
      "|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n",
      "|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n",
      "|5aa00529-0533-46b...|2019-01-30|      2017|218712|       2|        3|       1965|   14375|     2|         0|   7|\n",
      "|131492a1-72e2-4a8...|2020-02-08|      2017|419199|       2|        3|       2062|    8876|     2|         0|   6|\n",
      "|8d54a71b-c520-44e...|2019-07-21|      2010|323956|       2|        3|       1506|   11816|     1|         0|  25|\n",
      "|e81aacfe-17fe-46b...|2020-06-16|      2016|181925|       3|        3|       2137|   11709|     2|         0|  22|\n",
      "|2ed8d509-7372-46d...|2021-08-06|      2015|258710|       3|        3|       1918|    9666|     1|         0|  25|\n",
      "|f876d86f-3c9f-42b...|2019-02-27|      2011|167864|       3|        3|       2471|   13924|     2|         0|  15|\n",
      "|0a2bd445-8508-4d8...|2021-12-30|      2014|337527|       2|        3|       1926|   12556|     1|         0|  23|\n",
      "|941bad30-eb49-4a7...|2020-05-09|      2015|229896|       3|        3|       2197|    8641|     1|         0|   3|\n",
      "|dd61eb34-6589-4c0...|2021-07-25|      2016|210247|       3|        2|       1672|   11986|     2|         0|  28|\n",
      "|f1e4cef7-d151-439...|2019-02-01|      2011|398667|       2|        3|       2331|   11356|     1|         0|   7|\n",
      "|ea620c7b-c2f7-4c6...|2021-05-31|      2011|437958|       3|        3|       2356|   11052|     1|         0|  26|\n",
      "|f233cb41-6f33-4b0...|2021-07-18|      2016|437375|       4|        3|       1704|   11721|     2|         0|  34|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|      2015|288650|       2|        3|       2100|   10419|     2|         0|   7|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|      2015|308313|       3|        3|       1960|    9453|     2|         0|   2|\n",
      "|4566cd2a-ac6e-435...|2019-07-15|      2016|177541|       3|        3|       2130|   10517|     2|         0|  25|\n",
      "+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 10 - Spark operation - Parquet file created successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.278261 \u001b[33mSTEP 10 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.278653 \u001b[33mSTEP 10 - ELAPSED TIME: 0:00:00.801336 seconds=========\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 10 - Partition by the \"date_built\" field on the formatted parquet home sales data \n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 10 - FORMATTED PARQUET============================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  home_df.write.parquet('home_parquet', mode='overwrite',partitionBy='date_built')\n",
    "  home_df.show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 10 - Spark operation - Parquet file created successfully.\")\n",
    "  print()   \n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 10 - DONE=========================================\")\n",
    "step10_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 10 - ELAPSED TIME: {step10_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 11 - Read the parquet formatted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AZ7BgY61sRqY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.282849 \u001b[33mSTEP 11 - READ PARQUET=================================\u001b[37m\n",
      "\u001b[32m\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|                  id|      date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|date_built|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|2ed8d509-7372-46d...|2021-08-06|258710|       3|        3|       1918|    9666|     1|         0|  25|      2015|\n",
      "|941bad30-eb49-4a7...|2020-05-09|229896|       3|        3|       2197|    8641|     1|         0|   3|      2015|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|288650|       2|        3|       2100|   10419|     2|         0|   7|      2015|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|308313|       3|        3|       1960|    9453|     2|         0|   2|      2015|\n",
      "|d715f295-2fbf-4e9...|2021-05-17|391574|       3|        2|       1635|    8040|     2|         0|  10|      2015|\n",
      "|a18515a2-86f3-46b...|2022-02-18|419543|       3|        2|       1642|   12826|     2|         0|  24|      2015|\n",
      "|98f6a9ad-8870-474...|2022-05-07|136752|       2|        3|       1701|   10771|     2|         0|   5|      2015|\n",
      "|7ac67498-b6f3-403...|2021-05-12|349318|       4|        3|       2417|   11304|     2|         0|  37|      2015|\n",
      "|c9bfdb1c-2499-4e3...|2021-12-07|268874|       2|        2|       1537|   12177|     1|         0|  10|      2015|\n",
      "|34c31a34-220d-469...|2019-02-06|409011|       3|        3|       2356|   10507|     1|         0|   1|      2015|\n",
      "|be0ccb95-415d-411...|2020-05-15|425154|       4|        3|       2120|   14229|     2|         0|   4|      2015|\n",
      "|e9031a86-1294-444...|2021-10-09|222322|       4|        3|       1928|   10510|     1|         0|  38|      2015|\n",
      "|e6d7c2a7-596e-4ec...|2019-03-15|131201|       4|        3|       1633|   14655|     1|         0|  22|      2015|\n",
      "|6683714b-3df7-454...|2022-02-01|333403|       4|        2|       2059|    9793|     2|         0|   4|      2015|\n",
      "|00fc996f-508c-430...|2021-07-15|373139|       3|        3|       1763|   11363|     1|         0|  39|      2015|\n",
      "|3d5545f8-bd3b-476...|2020-09-19|797862|       4|        6|       3494|   10385|     2|         0|  90|      2015|\n",
      "|ec6d357c-2435-43e...|2019-05-28|401792|       3|        2|       1627|   10765|     1|         0|  50|      2015|\n",
      "|c2be38fb-814a-403...|2020-03-20|352237|       3|        3|       2485|   10954|     2|         0|   6|      2015|\n",
      "|9570de1f-5a74-45b...|2021-11-29|298453|       3|        2|       2222|   10634|     1|         0|   6|      2015|\n",
      "|1baeff4f-fc00-489...|2020-12-17|152775|       3|        2|       1623|   13851|     1|         0|  41|      2015|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 11 - Spark operation - Parquet file read successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.434763 \u001b[33mSTEP 11 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.435109 \u001b[33mSTEP 11 - ELAPSED TIME: 0:00:00.151905 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 11 - Read the parquet formatted data.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 11 - READ PARQUET=================================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  parquet_home_df = spark.read.parquet('home_parquet')\n",
    "  parquet_home_df.show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 11 - Spark operation - Parquet file read successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 11 - DONE=========================================\")\n",
    "step11_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 11 - ELAPSED TIME: {step11_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 12 - Create a temporary table for the parquet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J6MJkHfvVcvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.439239 \u001b[33mSTEP 12 - CREATE PARQUET VIEW==========================\u001b[37m\n",
      "\u001b[32m\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|                  id|      date| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|date_built|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "|2ed8d509-7372-46d...|2021-08-06|258710|       3|        3|       1918|    9666|     1|         0|  25|      2015|\n",
      "|941bad30-eb49-4a7...|2020-05-09|229896|       3|        3|       2197|    8641|     1|         0|   3|      2015|\n",
      "|c797ca12-52cd-4b1...|2019-06-08|288650|       2|        3|       2100|   10419|     2|         0|   7|      2015|\n",
      "|0cfe57f3-28c2-472...|2019-10-04|308313|       3|        3|       1960|    9453|     2|         0|   2|      2015|\n",
      "|d715f295-2fbf-4e9...|2021-05-17|391574|       3|        2|       1635|    8040|     2|         0|  10|      2015|\n",
      "|a18515a2-86f3-46b...|2022-02-18|419543|       3|        2|       1642|   12826|     2|         0|  24|      2015|\n",
      "|98f6a9ad-8870-474...|2022-05-07|136752|       2|        3|       1701|   10771|     2|         0|   5|      2015|\n",
      "|7ac67498-b6f3-403...|2021-05-12|349318|       4|        3|       2417|   11304|     2|         0|  37|      2015|\n",
      "|c9bfdb1c-2499-4e3...|2021-12-07|268874|       2|        2|       1537|   12177|     1|         0|  10|      2015|\n",
      "|34c31a34-220d-469...|2019-02-06|409011|       3|        3|       2356|   10507|     1|         0|   1|      2015|\n",
      "|be0ccb95-415d-411...|2020-05-15|425154|       4|        3|       2120|   14229|     2|         0|   4|      2015|\n",
      "|e9031a86-1294-444...|2021-10-09|222322|       4|        3|       1928|   10510|     1|         0|  38|      2015|\n",
      "|e6d7c2a7-596e-4ec...|2019-03-15|131201|       4|        3|       1633|   14655|     1|         0|  22|      2015|\n",
      "|6683714b-3df7-454...|2022-02-01|333403|       4|        2|       2059|    9793|     2|         0|   4|      2015|\n",
      "|00fc996f-508c-430...|2021-07-15|373139|       3|        3|       1763|   11363|     1|         0|  39|      2015|\n",
      "|3d5545f8-bd3b-476...|2020-09-19|797862|       4|        6|       3494|   10385|     2|         0|  90|      2015|\n",
      "|ec6d357c-2435-43e...|2019-05-28|401792|       3|        2|       1627|   10765|     1|         0|  50|      2015|\n",
      "|c2be38fb-814a-403...|2020-03-20|352237|       3|        3|       2485|   10954|     2|         0|   6|      2015|\n",
      "|9570de1f-5a74-45b...|2021-11-29|298453|       3|        2|       2222|   10634|     1|         0|   6|      2015|\n",
      "|1baeff4f-fc00-489...|2020-12-17|152775|       3|        2|       1623|   13851|     1|         0|  41|      2015|\n",
      "+--------------------+----------+------+--------+---------+-----------+--------+------+----------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 12 - Spark operation - Parquet view created successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.480189 \u001b[33mSTEP 12 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.480504 \u001b[33mSTEP 12 - ELAPSED TIME: 0:00:00.040940 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 12 - Create a temporary table for the parquet data.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 12 - CREATE PARQUET VIEW==========================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  parquet_home_df.createOrReplaceTempView('parquet_temp_home')\n",
    "  parquet_home_df.show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 12 - Spark operation - Parquet view created successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 12 - DONE=========================================\")\n",
    "step12_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 12 - ELAPSED TIME: {step12_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 13 - Run the query that filters out the view ratings with average price of greater than or equal to $350,000 with the parquet DataFrame. Round your average to two decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_Vhb52rU1Sn",
    "outputId": "5420b7c8-7f4b-404f-fc91-f70a06039866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.484548 \u001b[33mSTEP 13 - REPEAT QUERY=================================\u001b[37m\n",
      "\u001b[32m\n",
      "+----+---------+\n",
      "|VIEW|  AVERAGE|\n",
      "+----+---------+\n",
      "| 100|1026669.5|\n",
      "|  51|788128.21|\n",
      "|  52|733780.26|\n",
      "|  53| 755214.8|\n",
      "|  54|798684.82|\n",
      "|  55|771153.32|\n",
      "|  56| 718176.4|\n",
      "|  57| 734340.5|\n",
      "|  58|759764.65|\n",
      "|  59| 791453.0|\n",
      "|  60|754939.65|\n",
      "|  61|746877.59|\n",
      "|  62|759150.14|\n",
      "|  63|711614.55|\n",
      "|  64|767036.67|\n",
      "|  65|736679.93|\n",
      "|  66| 712475.0|\n",
      "|  67|737970.96|\n",
      "|  68|716785.44|\n",
      "|  69|750537.94|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\u001b[32mStep 13 - Spark operation - Parquet query executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.654001 \u001b[33mSTEP 13 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.654311 \u001b[33mSTEP 13 - ELAPSED TIME: 0:00:00.169443 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 13 - Run the query that filters out the view ratings with average price of greater than or equal to $350,000 with the parquet DataFrame. Round your average to two decimal places. \n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 13 - REPEAT QUERY=================================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"SELECT view as VIEW, \\\n",
    "                    ROUND(AVG(price),2) AS AVERAGE \\\n",
    "               FROM parquet_temp_home \\\n",
    "               GROUP BY view \\\n",
    "             HAVING ROUND(AVG(price),2) >= 350000 \\\n",
    "             ORDER BY view\").show()\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 13 - Spark operation - Parquet query executed successfully.\")\n",
    "  print()\n",
    "  \n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 13 - DONE=========================================\")\n",
    "step13_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 13 - ELAPSED TIME: {step13_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 13.1 Determine the runtime and compare to the original runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEkIu5yYuWlW",
    "outputId": "db861ec0-49c1-4855-86b4-f360d566302e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.658133 \u001b[33mSTEP 13.1 - RUNTIME DIFFERENCE ========================\u001b[37m\n",
      "\u001b[32m\n",
      "Time required for a non-cached Query    : 0:00:00.190776\n",
      "Time required for a parquet cached Query: 0:00:00.169443\n",
      "Time difference                         : 0:00:00.021333\n",
      "\u001b[32m\n",
      "\u001b[37m2023-09-05 15:11:44.658690 \u001b[33mSTEP 13.1 - DONE=======================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.658952 \u001b[33mSTEP 13.1 - ELAPSED TIME: 0:00:00.000563 seconds=======\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 13.1 - Determine the runtime and compare it to the cached version.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 13.1 - RUNTIME DIFFERENCE ========================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "print(F\"Time required for a non-cached Query    : {step6_elapsed_time}\")\n",
    "print(F\"Time required for a parquet cached Query: {step13_elapsed_time}\")\n",
    "time_difference = step6_elapsed_time - step13_elapsed_time\n",
    "print(F\"Time difference                         : {time_difference}\")\n",
    "print(Fore.GREEN)\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 13.1 - DONE=======================================\")\n",
    "step131_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 13.1 - ELAPSED TIME: {step131_elapsed_time} seconds=======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 14 - Un-cache the home_sales temporary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjjYzQGjtbq8",
    "outputId": "5b8e7eaf-78eb-4eef-d29d-1be425668fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.662595 \u001b[33mSTEP 14 - UN-CACHE=====================================\u001b[37m\n",
      "\u001b[32m\n",
      "\u001b[32mStep 14 - Spark operation - Uncache executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.673542 \u001b[33mSTEP 14 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.673933 \u001b[33mSTEP 14 - ELAPSED TIME: 0:00:00.010939 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 14 - Un-cache the home_sales temporary table.\n",
    "#\n",
    "\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 14 - UN-CACHE=====================================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  spark.sql(\"uncache table home_sales\")\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 14 - Spark operation - Uncache executed successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 14 - DONE=========================================\")\n",
    "step14_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 14 - ELAPSED TIME: {step14_elapsed_time} seconds=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 15 - Check if the home_sales is no longer cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sy9NBvO7tlmm",
    "outputId": "a3d33ffb-4052-41c6-8040-bff5a22a2188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.678085 \u001b[33mSTEP 15 - CACHE= CHECK=================================\u001b[37m\n",
      "\u001b[32m\n",
      "home_sales is not cached\n",
      "\u001b[32mStep 15 - Spark operation - Cache check executed successfully.\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.680716 \u001b[33mSTEP 15 - DONE=========================================\u001b[37m\n",
      "\u001b[37m2023-09-05 15:11:44.680910 \u001b[33mSTEP 15 - ELAPSED TIME: 0:00:00.002632 seconds=========\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Step 15 - Check if the home_sales is no longer cached\n",
    "#\n",
    "start_time         = datetime.datetime.now()\n",
    "logStep(\"STEP 15 - CACHE= CHECK=================================\")\n",
    "\n",
    "print(Fore.GREEN)\n",
    "try:\n",
    "  if (spark.catalog.isCached('home_sales') == False):\n",
    "      print(\"home_sales is not cached\")\n",
    "  else:\n",
    "      print(\"home_sales is cached\")\n",
    "except Exception as e:\n",
    "  print(Fore.RED + F\"Exception: {e}\")\n",
    "  sys.exit(1)\n",
    "else:\n",
    "  print(Fore.GREEN + \"Step 15 - Spark operation - Cache check executed successfully.\")\n",
    "  print()\n",
    "\n",
    "end_time           = datetime.datetime.now()\n",
    "logStep(\"STEP 15 - DONE=========================================\")\n",
    "step15_elapsed_time = end_time - start_time\n",
    "logStep(F\"STEP 15 - ELAPSED TIME: {step15_elapsed_time} seconds=========\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m2023-09-05 15:11:44.685565 \u001b[33m=========TOTAL RUN TIME================================\u001b[37m\n",
      "\u001b[32m\n",
      "Total Runtime, per Step\n",
      "\n",
      "Step  0:   0:00:00.110893 seconds\n",
      "Step  1:   0:00:04.684461 seconds\n",
      "Step  2:   0:00:00.018361 seconds\n",
      "Step  3:   0:00:00.605779 seconds\n",
      "Step  4:   0:00:00.215014 seconds\n",
      "Step  5:   0:00:00.158371 seconds\n",
      "\u001b[31mStep  6:   0:00:00.190776 seconds - non-cached query\u001b[32m\n",
      "\u001b[32mStep  7:   0:00:00.341298 seconds\n",
      "Step  8:   0:00:00.006130 seconds\n",
      "\u001b[31mStep  9:   0:00:00.100561 seconds - cached query\n",
      "\u001b[32mStep  9.1: 0:00:00.001097 seconds\n",
      "Step 10:   0:00:00.801336 seconds\n",
      "Step 11:   0:00:00.151905 seconds\n",
      "Step 12:   0:00:00.040940 seconds\n",
      "\u001b[31mStep 13:   0:00:00.169443 seconds - parquet cached query\n",
      "\u001b[32mStep 13.1: 0:00:00.000563 seconds\n",
      "Step 14:   0:00:00.010939 seconds\n",
      "Step 15:   0:00:00.002632 seconds\n",
      "\u001b[33mTotal  :   0:00:07.610499 seconds\n",
      "\n",
      "\u001b[32mRuntime Reduction\n",
      "\n",
      "\u001b[31mCached Query Reduction  : 47.29%\n",
      "Parquet Query Reduction : 11.18%\n",
      "\n",
      "\u001b[37m2023-09-05 15:11:44.686399 \u001b[33m=========END============================================\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "logStep(\"=========TOTAL RUN TIME================================\")\n",
    "print(Fore.GREEN)\n",
    "print('Total Runtime, per Step')\n",
    "print('')\n",
    "print(F\"Step  0:   {step0_elapsed_time} seconds\")\n",
    "print(F\"Step  1:   {step1_elapsed_time} seconds\")\n",
    "print(F\"Step  2:   {step2_elapsed_time} seconds\")\n",
    "print(F\"Step  3:   {step3_elapsed_time} seconds\")\n",
    "print(F\"Step  4:   {step4_elapsed_time} seconds\")\n",
    "print(F\"Step  5:   {step5_elapsed_time} seconds\")\n",
    "print(F\"{Fore.RED}Step  6:   {step6_elapsed_time} seconds - non-cached query{Fore.GREEN}\")\n",
    "print(F\"{Fore.GREEN}Step  7:   {step7_elapsed_time} seconds\")\n",
    "print(F\"Step  8:   {step8_elapsed_time} seconds\")\n",
    "print(F\"{Fore.RED}Step  9:   {step9_elapsed_time} seconds - cached query\")\n",
    "print(F\"{Fore.GREEN}Step  9.1: {step91_elapsed_time} seconds\")\n",
    "print(F\"Step 10:   {step10_elapsed_time} seconds\")\n",
    "print(F\"Step 11:   {step11_elapsed_time} seconds\")\n",
    "print(F\"Step 12:   {step12_elapsed_time} seconds\")\n",
    "print(F\"{Fore.RED}Step 13:   {step13_elapsed_time} seconds - parquet cached query\")\n",
    "print(F\"{Fore.GREEN}Step 13.1: {step131_elapsed_time} seconds\")\n",
    "print(F\"Step 14:   {step14_elapsed_time} seconds\")\n",
    "print(F\"Step 15:   {step15_elapsed_time} seconds\")\n",
    "print(F\"{Fore.YELLOW}Total  :   {step0_elapsed_time + step1_elapsed_time + step2_elapsed_time + step3_elapsed_time + step4_elapsed_time + step5_elapsed_time + step6_elapsed_time + step7_elapsed_time + step8_elapsed_time + step9_elapsed_time + step91_elapsed_time + step10_elapsed_time + step11_elapsed_time + step12_elapsed_time + step13_elapsed_time + step131_elapsed_time + step14_elapsed_time + step15_elapsed_time} seconds\")\n",
    "print('')\n",
    "print(Fore.GREEN + 'Runtime Reduction')\n",
    "print('')\n",
    "print(F'{Fore.RED}Cached Query Reduction  : {100-(step9_elapsed_time/step6_elapsed_time*100):.2f}%')\n",
    "print(F'Parquet Query Reduction : {100-(step13_elapsed_time/step6_elapsed_time*100):.2f}%')\n",
    "print('')\n",
    "logStep(\"=========END============================================\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
